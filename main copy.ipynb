{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\.virtualenvs\\imitation\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\.virtualenvs\\imitation\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\.virtualenvs\\imitation\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\.virtualenvs\\imitation\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\.virtualenvs\\imitation\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\.virtualenvs\\imitation\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\.virtualenvs\\imitation\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\.virtualenvs\\imitation\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\.virtualenvs\\imitation\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\.virtualenvs\\imitation\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\.virtualenvs\\imitation\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\.virtualenvs\\imitation\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\.virtualenvs\\imitation\\lib\\site-packages\\stable_baselines\\__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines import logger\n",
    "\n",
    "class Dset(object):\n",
    "  def __init__(self, inputs, labels, randomize):\n",
    "    self.inputs = inputs\n",
    "    self.labels = labels\n",
    "    assert len(self.inputs) == len(self.labels)\n",
    "    self.randomize = randomize\n",
    "    self.num_pairs = len(inputs)\n",
    "    self.init_pointer()\n",
    "\n",
    "  def init_pointer(self):\n",
    "    self.pointer = 0\n",
    "    if self.randomize:\n",
    "      idx = np.arange(self.num_pairs)\n",
    "      np.random.shuffle(idx)\n",
    "      self.inputs = self.inputs[idx, :]\n",
    "      self.labels = self.labels[idx, :]\n",
    "\n",
    "  def get_next_batch(self, batch_size):\n",
    "    # if batch_size is negative -> return all\n",
    "    if batch_size < 0:\n",
    "      return self.inputs, self.labels\n",
    "    if self.pointer + batch_size >= self.num_pairs:\n",
    "      self.init_pointer()\n",
    "    end = self.pointer + batch_size\n",
    "    inputs = self.inputs[self.pointer:end, :]\n",
    "    labels = self.labels[self.pointer:end, :]\n",
    "    self.pointer = end\n",
    "    return inputs, labels\n",
    "\n",
    "\n",
    "class Custom_Dset(object):\n",
    "  def __init__(self, expert_path, train_fraction=0.7, randomize=True):\n",
    "    traj_data = np.load(expert_path)\n",
    "    obs = traj_data['obs'][:]\n",
    "    acs = traj_data['acs'][:]\n",
    "\n",
    "    # obs, acs: shape (N, L, ) + S where N = # episodes, L = episode length\n",
    "    # and S is the environment observation/action space.\n",
    "    # Flatten to (N * L, prod(S))\n",
    "    if len(obs.shape) > 2:\n",
    "      self.obs = np.reshape(obs, [-1, np.prod(obs.shape[2:])])\n",
    "      self.acs = np.reshape(acs, [-1, np.prod(acs.shape[2:])])\n",
    "    else:\n",
    "      self.obs = np.vstack(obs)\n",
    "      self.acs = np.vstack(acs)\n",
    "\n",
    "    # self.rets = traj_data['ep_rets'][:traj_limitation]\n",
    "    # self.avg_ret = sum(self.rets)/len(self.rets)\n",
    "    # self.std_ret = np.std(np.array(self.rets))\n",
    "    if len(self.acs) > 2:\n",
    "      self.acs = np.squeeze(self.acs)\n",
    "    assert len(self.obs) == len(self.acs)\n",
    "    # self.num_traj = min(traj_limitation, len(traj_data['obs']))\n",
    "    self.num_transition = len(self.obs)\n",
    "    self.randomize = randomize\n",
    "    self.dset = Dset(self.obs, self.acs, self.randomize)\n",
    "    # for behavior cloning\n",
    "    self.train_set = Dset(self.obs[:int(self.num_transition*train_fraction), :],\n",
    "                          self.acs[:int(self.num_transition *\n",
    "                                        train_fraction), :],\n",
    "                          self.randomize)\n",
    "    self.val_set = Dset(self.obs[int(self.num_transition*train_fraction):, :],\n",
    "                        self.acs[int(self.num_transition*train_fraction):, :],\n",
    "                        self.randomize)\n",
    "    self.log_info()\n",
    "\n",
    "  def log_info(self):\n",
    "    # logger.log(\"Total trajectories: %d\" % self.num_traj)\n",
    "    logger.log(\"Total transitions: %d\" % self.num_transition)\n",
    "  #   logger.log(\"Average returns: %f\" % self.avg_ret)\n",
    "  #   logger.log(\"Std for returns: %f\" % self.std_ret)\n",
    "\n",
    "  def get_next_batch(self, batch_size, split=None):\n",
    "    if split is None:\n",
    "      return self.dset.get_next_batch(batch_size)\n",
    "    elif split == 'train':\n",
    "      return self.train_set.get_next_batch(batch_size)\n",
    "    elif split == 'val':\n",
    "      return self.val_set.get_next_batch(batch_size)\n",
    "    else:\n",
    "      raise NotImplementedError\n",
    "\n",
    "  def plot(self):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.hist(self.rets)\n",
    "    plt.savefig(\"histogram_rets.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "class CustomEnv(gym.Env):\n",
    "  metadata = {\"render_modes\": [None, \"human\"], \"render_fps\": 10}\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.observation_space = spaces.Box(-np.inf, np.inf, shape=(45,), dtype=np.float32)\n",
    "    self.action_space = spaces.Box(-np.inf, np.inf, shape=(7,), dtype=np.float32)\n",
    "\n",
    "    self.render_mode = None\n",
    "\n",
    "  # def reset(self):\n",
    "  #   # We need the following line to seed self.np_random\n",
    "  #   # super().reset()\n",
    "\n",
    "  #   # Choose the agent's location uniformly at random\n",
    "  #   self._state = np.random.rand(45).astype('f')\n",
    "\n",
    "  #   return self._state\n",
    "\n",
    "  # def _get_info(self):\n",
    "  #   return None\n",
    "  \n",
    "  # def _get_obs(self):\n",
    "  #   return self._state\n",
    "\n",
    "  # def render(self):\n",
    "  #   pass\n",
    "\n",
    "  # def _render_frame(self):\n",
    "  #   pass\n",
    "\n",
    "  # def step(self, action):\n",
    "  #   self._state[-6:] = self._state[-6:] + action\n",
    "  #   # An episode is done iff the agent has reached the target\n",
    "\n",
    "  #   return self._state, 1 - np.linalg.norm(action, ord=2), np.linalg.norm(action, ord=2) == 0, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os.path as osp\n",
    "import gym\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines import logger\n",
    "from stable_baselines.common import tf_util as U\n",
    "from stable_baselines.common.mpi_adam import MpiAdam\n",
    "# from baselines.gail.run_mujoco import runne\n",
    "\n",
    "def learn(env, policy_func, dataset, optim_batch_size=128, max_iters=1e4,\n",
    "          adam_epsilon=1e-5, optim_stepsize=3e-4,\n",
    "          ckpt_dir=None, task_name=None,\n",
    "          verbose=False):\n",
    "\n",
    "  val_per_iter = int(max_iters/10)\n",
    "  ob_space = env.observation_space\n",
    "  ac_space = env.action_space\n",
    "  # Construct network for new policy\n",
    "  pi = policy_func(\"pi\", ob_space, ac_space)\n",
    "  # placeholder\n",
    "  # ob = U.get_placeholder_cached(name=\"ob\")\n",
    "  ob = tf.placeholder(tf.float32, (None, 45), name=\"pi/ob\")\n",
    "  ac = pi.pdtype.sample_placeholder([None])\n",
    "  # stochastic = U.get_placeholder_cached(name=\"stochastic\")\n",
    "  stochastic = tf.placeholder(tf.bool, (), name=\"pi/stochastic\")\n",
    "  loss = tf.reduce_mean(tf.square(ac-pi.ac))\n",
    "  var_list = pi.get_trainable_variables()\n",
    "  adam = MpiAdam(var_list, epsilon=adam_epsilon)\n",
    "  lossandgrad = U.function([ob, ac, stochastic], [\n",
    "                           loss]+[U.flatgrad(loss, var_list)])\n",
    "\n",
    "  U.initialize()\n",
    "  adam.sync()\n",
    "  logger.log(\"Pretraining with Behavior Cloning...\")\n",
    "  for iter_so_far in tqdm(range(int(max_iters))):\n",
    "    ob_expert, ac_expert = dataset.get_next_batch(optim_batch_size, 'train')\n",
    "    train_loss, g = lossandgrad(ob_expert, ac_expert, True)\n",
    "    adam.update(g, optim_stepsize)\n",
    "    if verbose and iter_so_far % val_per_iter == 0:\n",
    "      ob_expert, ac_expert = dataset.get_next_batch(-1, 'val')\n",
    "      val_loss, _ = lossandgrad(ob_expert, ac_expert, True)\n",
    "      logger.log(\"Training loss: {}, Validation loss: {}\".format(\n",
    "          train_loss, val_loss))\n",
    "\n",
    "  if ckpt_dir is None:\n",
    "    savedir_fname = tempfile.TemporaryDirectory().name\n",
    "  else:\n",
    "    savedir_fname = osp.join(ckpt_dir, task_name)\n",
    "  U.save_variables(savedir_fname, variables=pi.get_variables())\n",
    "  return savedir_fname, pi\n",
    "\n",
    "\n",
    "def get_task_name():\n",
    "  task_name = 'BC'\n",
    "  task_name += '.{}'.format('custom')\n",
    "  task_name += '.traj_limitation_{}'.format(-1)\n",
    "  task_name += \".seed_{}\".format(0)\n",
    "  return task_name\n",
    "\n",
    "\n",
    "def make_session(expert_path):\n",
    "  U.make_session(num_cpu=1).__enter__()\n",
    "  # set_global_seeds(0)\n",
    "  env = CustomEnv()\n",
    "\n",
    "  def policy_fn(name, ob_space, ac_space, reuse=False):\n",
    "    temp = MlpPolicy(tf.compat.v1.get_default_session(), ob_space=ob_space, ac_space=ac_space, n_env=1, n_steps=1e3, n_batch=128,\n",
    "                                reuse=reuse)\n",
    "    temp.action\n",
    "    return temp\n",
    "  # env = bench.Monitor(env, logger.get_dir() and\n",
    "  #                     osp.join(logger.get_dir(), \"monitor.json\"))\n",
    "  env.seed(0)\n",
    "\n",
    "  gym.logger.setLevel(logging.ERROR)\n",
    "  task_name = get_task_name()\n",
    "\n",
    "  dataset = Custom_Dset(expert_path=expert_path)\n",
    "\n",
    "  savedir_fname, pi = learn(env,\n",
    "                        policy_fn,\n",
    "                        dataset,\n",
    "                        max_iters=1e3,\n",
    "                        ckpt_dir='checkpoint',\n",
    "                        # log_dir=osp.join('log', task_name),\n",
    "                        task_name=task_name,\n",
    "                        verbose=True)\n",
    "  return savedir_fname, pi\n",
    "  avg_len, avg_ret = runner(env,\n",
    "                            policy_fn,\n",
    "                            savedir_fname,\n",
    "                            timesteps_per_batch=1024,\n",
    "                            number_trajs=10,\n",
    "                            stochastic_policy=False,\n",
    "                            save=False,\n",
    "                            reuse=True)\n",
    "\n",
    "  return avg_len, avg_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ahmad\\AppData\\Local\\Temp\\ipykernel_16340\\3621746887.py:2: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ob:0' shape=(?, 45) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.constant(pi, shape=(None, 45), dtype=np.float32)\n",
    "tf.placeholder(tf.float32, (None, 45), name=\"ob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import pytz\n",
    "\n",
    "data = pd.read_csv('data/data.csv')\n",
    "data['datetime'] = pd.to_datetime(\n",
    "    data['timestamp'], unit='ms', utc=True).dt.tz_convert(pytz.timezone('US/Mountain'))\n",
    "data.drop(['timestamp', 'scene name', 'Unnamed: 19'], axis=1, inplace=True)\n",
    "data.set_index(['datetime'], inplace=True)\n",
    "temp = ['rIndex position', 'rIndex rotation', 'rIndex velocity',\n",
    "        'rIndex angular velocity', 'lIndex position', 'lIndex rotation',\n",
    "        'lIndex velocity', 'lIndex angular velocity',\n",
    "        'gaze origin', 'gaze direction',\n",
    "        'head movement direction', 'head velocity', 'target velocity',\n",
    "        'target angular velocity', 'target position', 'target rotation']\n",
    "\n",
    "data[temp] = data[temp].applymap(literal_eval, na_action='ignore')\n",
    "dataset = pd.DataFrame()\n",
    "dataset['Is Eye Tracking Enabled and Valid'] = data['Is Eye Tracking Enabled and Valid'].resample('0.1S').mean().interpolate('time', limit_direction='both', limit=len(data['Is Eye Tracking Enabled and Valid'].index))\n",
    "for col in temp:\n",
    "  col_data = data[col]\n",
    "  dataset[f'{col}_x'] = col_data.apply(lambda x: x if not x == x else x[0]).resample('0.1S').mean().interpolate('time', limit_direction='both', limit=len(col_data.index))\n",
    "  dataset[f'{col}_y'] = col_data.apply(lambda x: x if not x == x else x[1]).resample('0.1S').mean().interpolate('time', limit_direction='both', limit=len(col_data.index))\n",
    "  dataset[f'{col}_z'] = col_data.apply(lambda x: x if not x == x else x[2]).resample('0.1S').mean().interpolate('time', limit_direction='both', limit=len(col_data.index))\n",
    "  if col.endswith('rotation'):\n",
    "    dataset[f'{col}_w'] = col_data.apply(lambda x: x if not x == x else x[3]).resample('0.1S').mean().interpolate('time', limit_direction='both', limit=len(col_data.index))\n",
    "\n",
    "\n",
    "events = pd.read_csv('data/events.csv', usecols=['timestamp', 'event'])\n",
    "events['datetime'] = pd.to_datetime(\n",
    "    events['timestamp'], unit='ms', utc=True).dt.tz_convert(pytz.timezone('US/Mountain'))\n",
    "events.set_index(['datetime'], inplace=True)\n",
    "collision_events = events[events['event'] == 'Left IndexTip']\n",
    "target_events = events[events['event'].str.match(r'^target')]\n",
    "target_events.tail()\n",
    "del events\n",
    "\n",
    "target_found = target_events[target_events['event'] == 'target_found']\n",
    "target_lost = target_events[target_events['event'] == 'target_lost']\n",
    "\n",
    "final_res = []\n",
    "for found, row in target_found.iterrows():\n",
    "  lost = target_lost[target_lost.index > found].iloc[0].name\n",
    "  mask = ((dataset.index >= found) & (dataset.index <= lost))\n",
    "  obs = dataset[mask].iloc[:-1, 0:-7]\n",
    "  acs = dataset[mask].iloc[1:, -7:]\n",
    "  final_res.append({'obs':obs, 'acs':acs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_obs = None\n",
    "concat_acs = None\n",
    "for i in final_res:\n",
    "  if concat_obs is None:\n",
    "    concat_obs = i['obs']\n",
    "    concat_acs = i['acs']\n",
    "    continue\n",
    "  concat_obs = np.concatenate([concat_obs, i['obs']])\n",
    "  concat_acs = np.concatenate([concat_acs, i['acs']])\n",
    "\n",
    "np.savez('test.npz', obs=concat_obs, acs=concat_acs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\.virtualenvs\\imitation\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\.virtualenvs\\imitation\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Total transitions: 19\n",
      "WARNING:tensorflow:From d:\\.virtualenvs\\imitation\\lib\\site-packages\\stable_baselines\\common\\policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\.virtualenvs\\imitation\\lib\\site-packages\\stable_baselines\\common\\policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000021E61A51B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000021E61A51B48>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000021E61A51B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000021E61A51B48>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From d:\\.virtualenvs\\imitation\\lib\\site-packages\\stable_baselines\\common\\tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\.virtualenvs\\imitation\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MlpPolicy' object has no attribute 'ac'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16340\\3286338438.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.npz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16340\\148206560.py\u001b[0m in \u001b[0;36mmake_session\u001b[1;34m(expert_path)\u001b[0m\n\u001b[0;32m     88\u001b[0m                         \u001b[1;31m# log_dir=osp.join('log', task_name),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                         \u001b[0mtask_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                         verbose=True)\n\u001b[0m\u001b[0;32m     91\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0msavedir_fname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m   avg_len, avg_ret = runner(env,\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16340\\148206560.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(env, policy_func, dataset, optim_batch_size, max_iters, adam_epsilon, optim_stepsize, ckpt_dir, task_name, verbose)\u001b[0m\n\u001b[0;32m     29\u001b[0m   \u001b[1;31m# stochastic = U.get_placeholder_cached(name=\"stochastic\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m   \u001b[0mstochastic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pi/stochastic\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m   \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mac\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mac\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m   \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trainable_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m   \u001b[0madam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMpiAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madam_epsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MlpPolicy' object has no attribute 'ac'"
     ]
    }
   ],
   "source": [
    "_, pi = make_session('test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi.get_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf2onnx import tf_loader\n",
    "\n",
    "tf_loader.from_checkpoint('checkpoint/BC.custom.traj_limitation_-1.seed_0', 'input:0', 'output:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "317275edef059c081c8f32f3d67c6af1b2c1ab1ba9385db8161d12c9ef49d86a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
