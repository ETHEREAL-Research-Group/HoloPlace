{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from baselines import logger\n",
    "\n",
    "class Dset(object):\n",
    "  def __init__(self, inputs, labels, randomize):\n",
    "    self.inputs = inputs\n",
    "    self.labels = labels\n",
    "    assert len(self.inputs) == len(self.labels)\n",
    "    self.randomize = randomize\n",
    "    self.num_pairs = len(inputs)\n",
    "    self.init_pointer()\n",
    "\n",
    "  def init_pointer(self):\n",
    "    self.pointer = 0\n",
    "    if self.randomize:\n",
    "      idx = np.arange(self.num_pairs)\n",
    "      np.random.shuffle(idx)\n",
    "      self.inputs = self.inputs[idx, :]\n",
    "      self.labels = self.labels[idx, :]\n",
    "\n",
    "  def get_next_batch(self, batch_size):\n",
    "    # if batch_size is negative -> return all\n",
    "    if batch_size < 0:\n",
    "      return self.inputs, self.labels\n",
    "    if self.pointer + batch_size >= self.num_pairs:\n",
    "      self.init_pointer()\n",
    "    end = self.pointer + batch_size\n",
    "    inputs = self.inputs[self.pointer:end, :]\n",
    "    labels = self.labels[self.pointer:end, :]\n",
    "    self.pointer = end\n",
    "    return inputs, labels\n",
    "\n",
    "\n",
    "class Custom_Dset(object):\n",
    "  def __init__(self, expert_path, train_fraction=0.7, randomize=True):\n",
    "    traj_data = np.load(expert_path)\n",
    "    obs = traj_data['obs'][:]\n",
    "    acs = traj_data['acs'][:]\n",
    "\n",
    "    # obs, acs: shape (N, L, ) + S where N = # episodes, L = episode length\n",
    "    # and S is the environment observation/action space.\n",
    "    # Flatten to (N * L, prod(S))\n",
    "    if len(obs.shape) > 2:\n",
    "      self.obs = np.reshape(obs, [-1, np.prod(obs.shape[2:])])\n",
    "      self.acs = np.reshape(acs, [-1, np.prod(acs.shape[2:])])\n",
    "    else:\n",
    "      self.obs = np.vstack(obs)\n",
    "      self.acs = np.vstack(acs)\n",
    "\n",
    "    # self.rets = traj_data['ep_rets'][:traj_limitation]\n",
    "    # self.avg_ret = sum(self.rets)/len(self.rets)\n",
    "    # self.std_ret = np.std(np.array(self.rets))\n",
    "    if len(self.acs) > 2:\n",
    "      self.acs = np.squeeze(self.acs)\n",
    "    assert len(self.obs) == len(self.acs)\n",
    "    # self.num_traj = min(traj_limitation, len(traj_data['obs']))\n",
    "    self.num_transition = len(self.obs)\n",
    "    self.randomize = randomize\n",
    "    self.dset = Dset(self.obs, self.acs, self.randomize)\n",
    "    # for behavior cloning\n",
    "    self.train_set = Dset(self.obs[:int(self.num_transition*train_fraction), :],\n",
    "                          self.acs[:int(self.num_transition *\n",
    "                                        train_fraction), :],\n",
    "                          self.randomize)\n",
    "    self.val_set = Dset(self.obs[int(self.num_transition*train_fraction):, :],\n",
    "                        self.acs[int(self.num_transition*train_fraction):, :],\n",
    "                        self.randomize)\n",
    "    self.log_info()\n",
    "\n",
    "  def log_info(self):\n",
    "    # logger.log(\"Total trajectories: %d\" % self.num_traj)\n",
    "    logger.log(\"Total transitions: %d\" % self.num_transition)\n",
    "  #   logger.log(\"Average returns: %f\" % self.avg_ret)\n",
    "  #   logger.log(\"Std for returns: %f\" % self.std_ret)\n",
    "\n",
    "  def get_next_batch(self, batch_size, split=None):\n",
    "    if split is None:\n",
    "      return self.dset.get_next_batch(batch_size)\n",
    "    elif split == 'train':\n",
    "      return self.train_set.get_next_batch(batch_size)\n",
    "    elif split == 'val':\n",
    "      return self.val_set.get_next_batch(batch_size)\n",
    "    else:\n",
    "      raise NotImplementedError\n",
    "\n",
    "  def plot(self):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.hist(self.rets)\n",
    "    plt.savefig(\"histogram_rets.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CustomEnv(gym.Env):\n",
    "  metadata = {\"render_modes\": [None, \"human\"], \"render_fps\": 10}\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.observation_space = spaces.Box(-np.inf, np.inf, shape=(45,), dtype=np.float32)\n",
    "    self.action_space = spaces.Box(-np.inf, np.inf, shape=(7,), dtype=np.float32)\n",
    "\n",
    "    self.render_mode = None\n",
    "\n",
    "  # def reset(self):\n",
    "  #   # We need the following line to seed self.np_random\n",
    "  #   # super().reset()\n",
    "\n",
    "  #   # Choose the agent's location uniformly at random\n",
    "  #   self._state = np.random.rand(45).astype('f')\n",
    "\n",
    "  #   return self._state\n",
    "\n",
    "  # def _get_info(self):\n",
    "  #   return None\n",
    "  \n",
    "  # def _get_obs(self):\n",
    "  #   return self._state\n",
    "\n",
    "  # def render(self):\n",
    "  #   pass\n",
    "\n",
    "  # def _render_frame(self):\n",
    "  #   pass\n",
    "\n",
    "  # def step(self, action):\n",
    "  #   self._state[-6:] = self._state[-6:] + action\n",
    "  #   # An episode is done iff the agent has reached the target\n",
    "\n",
    "  #   return self._state, 1 - np.linalg.norm(action, ord=2), np.linalg.norm(action, ord=2) == 0, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import tempfile\n",
    "import os.path as osp\n",
    "import gym\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from baselines.gail import mlp_policy\n",
    "from baselines import bench\n",
    "from baselines import logger\n",
    "from baselines.common import set_global_seeds, tf_util as U\n",
    "from baselines.common.misc_util import boolean_flag\n",
    "from baselines.common.mpi_adam import MpiAdam\n",
    "from baselines.gail.run_mujoco import runner\n",
    "\n",
    "\n",
    "def argsparser():\n",
    "  parser = argparse.ArgumentParser(\n",
    "      \"Tensorflow Implementation of Behavior Cloning\")\n",
    "  parser.add_argument('--env_id', help='environment ID', default='Hopper-v2')\n",
    "  parser.add_argument('--seed', help='RNG seed', type=int, default=0)\n",
    "  parser.add_argument('--expert_path', type=str,\n",
    "                      default='data/deterministic.trpo.Hopper.0.00.npz')\n",
    "  parser.add_argument('--checkpoint_dir',\n",
    "                      help='the directory to save model', default='checkpoint')\n",
    "  parser.add_argument(\n",
    "      '--log_dir', help='the directory to save log file', default='log')\n",
    "  #  Mujoco Dataset Configuration\n",
    "  parser.add_argument('--traj_limitation', type=int, default=-1)\n",
    "  # Network Configuration (Using MLP Policy)\n",
    "  parser.add_argument('--policy_hidden_size', type=int, default=100)\n",
    "  # for evaluatation\n",
    "  boolean_flag(parser, 'stochastic_policy', default=False,\n",
    "               help='use stochastic/deterministic policy to evaluate')\n",
    "  boolean_flag(parser, 'save_sample', default=False,\n",
    "               help='save the trajectories or not')\n",
    "  parser.add_argument(\n",
    "      '--BC_max_iter', help='Max iteration for training BC', type=int, default=1e5)\n",
    "  return parser.parse_args()\n",
    "\n",
    "\n",
    "def learn(env, policy_func, dataset, optim_batch_size=128, max_iters=1e4,\n",
    "          adam_epsilon=1e-5, optim_stepsize=3e-4,\n",
    "          ckpt_dir=None, task_name=None,\n",
    "          verbose=False):\n",
    "\n",
    "  val_per_iter = int(max_iters/10)\n",
    "  ob_space = env.observation_space\n",
    "  ac_space = env.action_space\n",
    "  # Construct network for new policy\n",
    "  pi = policy_func(\"pi\", ob_space, ac_space)\n",
    "  # placeholder\n",
    "  ob = U.get_placeholder_cached(name=\"ob\")\n",
    "  logger.error('fuuuuuuuuuuuuuuuuck')\n",
    "  logger.error(ob)\n",
    "\n",
    "  ac = pi.pdtype.sample_placeholder([None])\n",
    "  stochastic = U.get_placeholder_cached(name=\"stochastic\")\n",
    "  logger.error(stochastic)\n",
    "  loss = tf.reduce_mean(tf.square(ac-pi.ac))\n",
    "  var_list = pi.get_trainable_variables()\n",
    "  adam = MpiAdam(var_list, epsilon=adam_epsilon)\n",
    "  lossandgrad = U.function([ob, ac, stochastic], [\n",
    "                           loss]+[U.flatgrad(loss, var_list)])\n",
    "\n",
    "  U.initialize()\n",
    "  adam.sync()\n",
    "  logger.log(\"Pretraining with Behavior Cloning...\")\n",
    "  for iter_so_far in tqdm(range(int(max_iters))):\n",
    "    ob_expert, ac_expert = dataset.get_next_batch(optim_batch_size, 'train')\n",
    "    train_loss, g = lossandgrad(ob_expert, ac_expert, True)\n",
    "    adam.update(g, optim_stepsize)\n",
    "    if verbose and iter_so_far % val_per_iter == 0:\n",
    "      ob_expert, ac_expert = dataset.get_next_batch(-1, 'val')\n",
    "      val_loss, _ = lossandgrad(ob_expert, ac_expert, True)\n",
    "      logger.log(\"Training loss: {}, Validation loss: {}\".format(\n",
    "          train_loss, val_loss))\n",
    "\n",
    "  if ckpt_dir is None:\n",
    "    savedir_fname = tempfile.TemporaryDirectory().name\n",
    "  else:\n",
    "    savedir_fname = osp.join(ckpt_dir, task_name)\n",
    "  U.save_variables(savedir_fname, variables=pi.get_variables())\n",
    "  return savedir_fname, pi\n",
    "\n",
    "\n",
    "def get_task_name():\n",
    "  task_name = 'BC'\n",
    "  task_name += '.{}'.format('custom')\n",
    "  task_name += '.traj_limitation_{}'.format(-1)\n",
    "  task_name += \".seed_{}\".format(0)\n",
    "  return task_name\n",
    "\n",
    "\n",
    "def make_session(expert_path):\n",
    "  U.make_session(num_cpu=1).__enter__()\n",
    "  set_global_seeds(0)\n",
    "  env = CustomEnv()\n",
    "\n",
    "  def policy_fn(name, ob_space, ac_space, reuse=False):\n",
    "    temp = mlp_policy.MlpPolicy(name=name, ob_space=ob_space, ac_space=ac_space,\n",
    "                                reuse=reuse, hid_size=100, num_hid_layers=2)\n",
    "    temp.ac\n",
    "    return temp\n",
    "  env = bench.Monitor(env, logger.get_dir() and\n",
    "                      osp.join(logger.get_dir(), \"monitor.json\"))\n",
    "  env.seed(0)\n",
    "\n",
    "  gym.logger.setLevel(logging.ERROR)\n",
    "  task_name = get_task_name()\n",
    "\n",
    "  dataset = Custom_Dset(expert_path=expert_path)\n",
    "\n",
    "  savedir_fname, pi = learn(env,\n",
    "                        policy_fn,\n",
    "                        dataset,\n",
    "                        max_iters=1e3,\n",
    "                        ckpt_dir='checkpoint',\n",
    "                        # log_dir=osp.join('log', task_name),\n",
    "                        task_name=task_name,\n",
    "                        verbose=True)\n",
    "  return savedir_fname, pi\n",
    "  avg_len, avg_ret = runner(env,\n",
    "                            policy_fn,\n",
    "                            savedir_fname,\n",
    "                            timesteps_per_batch=1024,\n",
    "                            number_trajs=10,\n",
    "                            stochastic_policy=False,\n",
    "                            save=False,\n",
    "                            reuse=True)\n",
    "\n",
    "  return avg_len, avg_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import pytz\n",
    "\n",
    "data = pd.read_csv('data/data.csv')\n",
    "data['datetime'] = pd.to_datetime(\n",
    "    data['timestamp'], unit='ms', utc=True).dt.tz_convert(pytz.timezone('US/Mountain'))\n",
    "data.drop(['timestamp', 'scene name', 'Unnamed: 19'], axis=1, inplace=True)\n",
    "data.set_index(['datetime'], inplace=True)\n",
    "temp = ['rIndex position', 'rIndex rotation', 'rIndex velocity',\n",
    "        'rIndex angular velocity', 'lIndex position', 'lIndex rotation',\n",
    "        'lIndex velocity', 'lIndex angular velocity',\n",
    "        'gaze origin', 'gaze direction',\n",
    "        'head movement direction', 'head velocity', 'target velocity',\n",
    "        'target angular velocity', 'target position', 'target rotation']\n",
    "\n",
    "data[temp] = data[temp].applymap(literal_eval, na_action='ignore')\n",
    "dataset = pd.DataFrame()\n",
    "dataset['Is Eye Tracking Enabled and Valid'] = data['Is Eye Tracking Enabled and Valid'].resample('0.1S').mean().interpolate('time', limit_direction='both', limit=len(data['Is Eye Tracking Enabled and Valid'].index))\n",
    "for col in temp:\n",
    "  col_data = data[col]\n",
    "  dataset[f'{col}_x'] = col_data.apply(lambda x: x if not x == x else x[0]).resample('0.1S').mean().interpolate('time', limit_direction='both', limit=len(col_data.index))\n",
    "  dataset[f'{col}_y'] = col_data.apply(lambda x: x if not x == x else x[1]).resample('0.1S').mean().interpolate('time', limit_direction='both', limit=len(col_data.index))\n",
    "  dataset[f'{col}_z'] = col_data.apply(lambda x: x if not x == x else x[2]).resample('0.1S').mean().interpolate('time', limit_direction='both', limit=len(col_data.index))\n",
    "  if col.endswith('rotation'):\n",
    "    dataset[f'{col}_w'] = col_data.apply(lambda x: x if not x == x else x[3]).resample('0.1S').mean().interpolate('time', limit_direction='both', limit=len(col_data.index))\n",
    "\n",
    "\n",
    "events = pd.read_csv('data/events.csv', usecols=['timestamp', 'event'])\n",
    "events['datetime'] = pd.to_datetime(\n",
    "    events['timestamp'], unit='ms', utc=True).dt.tz_convert(pytz.timezone('US/Mountain'))\n",
    "events.set_index(['datetime'], inplace=True)\n",
    "collision_events = events[events['event'] == 'Left IndexTip']\n",
    "target_events = events[events['event'].str.match(r'^target')]\n",
    "target_events.tail()\n",
    "del events\n",
    "\n",
    "target_found = target_events[target_events['event'] == 'target_found']\n",
    "target_lost = target_events[target_events['event'] == 'target_lost']\n",
    "\n",
    "final_res = []\n",
    "for found, row in target_found.iterrows():\n",
    "  lost = target_lost[target_lost.index > found].iloc[0].name\n",
    "  mask = ((dataset.index >= found) & (dataset.index <= lost))\n",
    "  obs = dataset[mask].iloc[:-1, 0:-7]\n",
    "  acs = dataset[mask].iloc[1:, -7:]\n",
    "  final_res.append({'obs':obs, 'acs':acs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_obs = None\n",
    "concat_acs = None\n",
    "for i in final_res:\n",
    "  if concat_obs is None:\n",
    "    concat_obs = i['obs']\n",
    "    concat_acs = i['acs']\n",
    "    continue\n",
    "  concat_obs = np.concatenate([concat_obs, i['obs']])\n",
    "  concat_acs = np.concatenate([concat_acs, i['acs']])\n",
    "\n",
    "np.savez('test.npz', obs=concat_obs, acs=concat_acs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pi = make_session('test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi.get_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf2onnx import tf_loader\n",
    "\n",
    "tf_loader.from_checkpoint('checkpoint/BC.custom.traj_limitation_-1.seed_0', 'input:0', 'output:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "317275edef059c081c8f32f3d67c6af1b2c1ab1ba9385db8161d12c9ef49d86a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
